# Design Document: NeuroSym.js & NeuroJSON Protocol

## 1. Executive Summary

**NeuroSym.js** is a lightweight, zero-dependency JavaScript library for **Neurosymbolic AI**. It bridges the gap between neural networks (fuzziness, learning) and symbolic logic (guarantees, explainability).

It implements **Logical Neural Networks (LNN)** concepts using a **Parsimonious Data Protocol (NeuroJSON)**. It is designed to run in any JS environment (Node.js, Browser, Edge Workers).

**Core Philosophy:** "Code as Data." The logic of the AI is defined in a serializable JSON graph, not in hardcoded functions.

---

## 2. Architecture Overview

The system is composed of three decoupled modules:

### 2.1 Logic Core (Stateless Math)
- Implements Lukasiewicz T-Norms for continuous logic (0.0 to 1.0)
- Implements "Inhibition" logic for Argumentation (Attacks)
- Pure functions only. No side effects.

### 2.2 NeuroGraph (State Manager)
- An in-memory graph structure representing the "World State"
- Manages **Variables** (Nodes) and **Priors** (Initial Beliefs)
- Handles "Locking" (Evidence injection)

### 2.3 Inference Engine (The Solver)
- Iteratively propagates truth values through the graph (Diffusion)
- Supports **Forward Chaining** (Data -> Conclusions)
- Supports **Bayesian Inference** (Evidence -> Probabilities)
- Includes a **Training Loop** (Backpropagation-lite) to learn weights

---

## 3. The NeuroJSON Specification

All logic must be serializable to this JSON format. This allows the logic to be stored in databases or generated by LLMs.

### 3.1 Schema Definition

```json
{
  "version": "1.0",
  "variables": {
    "concept_a": { "type": "bool", "prior": 0.5 },
    "concept_b": { "type": "bool", "prior": 0.1 }
  },
  "rules": [
    {
      "id": "rule_1",
      "type": "IMPLICATION",
      "inputs": ["concept_a"],
      "output": "concept_b",
      "op": "IDENTITY", 
      "weight": 0.9 
    }
  ],
  "constraints": [
    {
      "id": "attack_1",
      "type": "ATTACK",
      "source": "concept_c",
      "target": "concept_b",
      "weight": 1.0
    }
  ]
}
```

### 3.2 Supported Operations

| Operation | Formula | Description |
|-----------|---------|-------------|
| `AND` | `max(0, sum(inputs) - (n-1))` | Strict requirement of all inputs |
| `OR` | `min(1, sum(inputs))` | Any input contributes |
| `NOT` | `1 - input` | Negation |
| `IDENTITY` | `input` | Direct pass-through |
| `INHIBIT` | `target * (1 - attacker * weight)` | Attack relation |

---

## 4. Lukasiewicz Logic

We use Lukasiewicz T-Norms because they:
- Satisfy logical properties (associativity, commutativity)
- Allow for "partial" truth values (fuzzy reasoning)
- Have well-defined gradients for learning

### Key Formulas

```
NOT(a) = 1 - a
AND(a, b) = max(0, a + b - 1)
OR(a, b) = min(1, a + b)
IMPLIES(a, b) = min(1, 1 - a + b)
EQUIVALENT(a, b) = 1 - |a - b|
```

---

## 5. API Reference

### NeuroEngine (Main Class)

```typescript
const ai = new NeuroEngine(schema);

// Inference
const result = ai.run(evidence?, iterations?);

// Training
ai.train(examples, epochs?);

// Export
const trained = ai.export();
```

### Training Formula

Weights are updated using heuristic gradient descent:

```
Weight_New = Weight_Old + (Error × LearningRate × Input_Strength)
```

---

## 6. Use Cases

1. **Expert Systems**: Encode domain knowledge as rules
2. **Argumentation**: Model debates with pro/con arguments
3. **Risk Assessment**: Compute fuzzy risk scores
4. **Causal Reasoning**: "What if" queries on causal graphs
5. **Explainable AI**: Logic is inspectable and editable
